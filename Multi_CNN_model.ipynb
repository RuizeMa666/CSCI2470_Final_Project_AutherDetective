{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import chardet\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "import time\n",
    "\n",
    "# Display plots inline\n",
    "# % matplotlib inline\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import MinMaxScaler, MaxAbsScaler\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, make_scorer, confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Flatten, Dropout, Embedding\n",
    "from keras.layers.convolutional import Conv1D, MaxPooling1D\n",
    "# from keras.layers.merge import concatenate\n",
    "from tensorflow.keras.layers import concatenate, Add, Subtract\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.callbacks import ModelCheckpoint \n",
    "\n",
    "from scipy import sparse, stats\n",
    "import random\n",
    "np.random.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chardet\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "with open(r\"c:\\Users\\guyu8\\Documents\\WeChat Files\\wxid_8m1bo9kcmqmy21\\FileStorage\\File\\2024-05\\data_with_genre.csv\", 'rb') as file:\n",
    "    result = chardet.detect(file.read())\n",
    "    encoding = result['encoding']\n",
    "\n",
    "data = pd.read_csv(r\"c:\\Users\\guyu8\\Documents\\WeChat Files\\wxid_8m1bo9kcmqmy21\\FileStorage\\File\\2024-05\\data_with_genre.csv\", encoding=encoding)\n",
    "text = list(data['text'].values)\n",
    "author = list(data['author'].values)\n",
    "\n",
    "normed_text = []\n",
    "for excerpt in text:\n",
    "    excerpt = excerpt.replace('\\xa0', '')\n",
    "    excerpt = excerpt.lower().replace(\"'\", \" \")\n",
    "    excerpt = excerpt.translate(str.maketrans('', '', string.punctuation))\n",
    "    excerpt = excerpt.replace('“', '').replace('”', '')\n",
    "    normed_text.append(excerpt)\n",
    "\n",
    "tokens = [word_tokenize(sentence) for sentence in normed_text]\n",
    "flat_tokens = [token for sublist in tokens for token in sublist]\n",
    "\n",
    "unique_words = set(flat_tokens)\n",
    "vocab = {word: idx for idx, word in enumerate(sorted(unique_words))}\n",
    "\n",
    "train_data, test_data, author_train, author_test = train_test_split(normed_text, author, test_size=0.2, random_state=5)\n",
    "train_tokens = [word_tokenize(sentence) for sentence in train_data]\n",
    "# train_tokens = [element for sublist in train_tokens for element in sublist]\n",
    "\n",
    "test_tokens = [word_tokenize(sentence) for sentence in test_data]\n",
    "normed_text = [word_tokenize(sentence) for sentence in normed_text]\n",
    "\n",
    "# train_data = [[vocab[word] for word in word_tokenize(text)] for text in train_data]\n",
    "# test_data = [[vocab[word] for word in word_tokenize(text)] for text in test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_n_grams(sentence_list, n, vocab_size, seq_size):\n",
    "    n_gram_list = []\n",
    "    for sentence in sentence_list:\n",
    "        n_grams = [sentence[i:i+n] for i in range(len(sentence) - n + 1)]\n",
    "        combined_n_grams = [\" \".join(sublist) for sublist in n_grams]\n",
    "        new_string = [\"\".join(word.split()) for word in combined_n_grams]\n",
    "        new_string = \" \".join(new_string)\n",
    "        hot = one_hot(new_string, round(vocab_size*1.3))\n",
    "\n",
    "        hot_len = len(hot)\n",
    "        if hot_len >= seq_size:\n",
    "            hot = hot[0:seq_size]\n",
    "        else:\n",
    "            diff = seq_size - hot_len\n",
    "            extra = [0]*diff\n",
    "            hot = hot + extra\n",
    "\n",
    "        n_gram_list.append(hot)\n",
    "        \n",
    "    n_gram_array = np.array(n_gram_list)\n",
    "    \n",
    "    return n_gram_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocab_size(sentence_list, n, seq_size):\n",
    "\n",
    "    token_vocab = []\n",
    "\n",
    "    for sentence in sentence_list:\n",
    "        n_grams = [sentence[i:i+n] for i in range(len(sentence) - n + 1)]\n",
    "        combined_three_grams = [\" \".join(sublist) for sublist in n_grams]\n",
    "        new_string = [\"\".join(word.split()) for word in combined_three_grams]\n",
    "        token_vocab.append(new_string)\n",
    "    flattened_list = [item for sublist in token_vocab for item in sublist]\n",
    "\n",
    "    n_gram_cnt = Counter(flattened_list)\n",
    "    vocab_size = len(n_gram_cnt)\n",
    "    \n",
    "    \n",
    "    return vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gram1_train = create_n_grams(train_tokens, 1, get_vocab_size(train_tokens, 1, 300), 300)\n",
    "gram1_test = create_n_grams(test_tokens, 1, get_vocab_size(test_tokens, 1, 300), 300)\n",
    "gram1 = create_n_grams(normed_text, 1, get_vocab_size(normed_text, 1, 300), 300)\n",
    "max_1gram = np.max(gram1_train)\n",
    "max_1gram = np.max(gram1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# author_lb = LabelBinarizer()\n",
    "# author_lb.fit(author_train)\n",
    "# author_train_hot = author_lb.transform(author_train)\n",
    "# author_test_hot = author_lb.transform(author_test)\n",
    "\n",
    "author_lb = LabelBinarizer()\n",
    "author_lb.fit(author)\n",
    "author_hot = author_lb.transform(author)\n",
    "author_test_hot = author_lb.transform(author_test)\n",
    "author_train_hot = author_lb.transform(author_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leo Tolstoy\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(author[1])\n",
    "print(author_hot[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leo Tolstoy\n"
     ]
    }
   ],
   "source": [
    "print(author_test[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    }
   ],
   "source": [
    "print(np.argmax(author_test_hot[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer\n",
    "\n",
    "class AdaptiveDropout(Layer):\n",
    "    def __init__(self, initial_rate=0.2):\n",
    "        super(AdaptiveDropout, self).__init__()\n",
    "        self.dropout_rate = tf.Variable(initial_rate, trainable=False)\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        if training:\n",
    "            return tf.nn.dropout(inputs, rate=self.dropout_rate)\n",
    "        return inputs\n",
    "\n",
    "    def set_rate(self, new_rate):\n",
    "        self.dropout_rate.assign(new_rate)\n",
    "\n",
    "class AdjustDropoutRateCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, model, threshold=0.90, increase_by=0.1):\n",
    "        super().__init__()\n",
    "        for layer in model.layers:\n",
    "            if isinstance(layer, AdaptiveDropout):\n",
    "                layer_adap = layer\n",
    "                break\n",
    "        self.layer = layer_adap\n",
    "        self.threshold = threshold\n",
    "        self.increase_by = increase_by\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if logs['accuracy'] > self.threshold:\n",
    "            new_rate = min(1.0, self.layer.dropout_rate + self.increase_by)\n",
    "            self.layer.set_rate(new_rate)\n",
    "            print(f\"Epoch {epoch+1}: Increasing dropout rate to {new_rate:.2f}\")\n",
    "        else:\n",
    "            print(f\"Epoch {epoch+1}: Current accuracy {logs['accuracy']:.2f} is below threshold\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Embedding, Dropout, Conv1D, MaxPooling1D, Flatten, Dense, concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def define_model2(input_len, output_size, vocab_size, embedding_dim, verbose=True,\n",
    "                  drop_out_pct=0.25, conv_filters=500, activation_fn='leaky_relu',\n",
    "                  pool_size=2, learning=0.001, init_mode_embedding=None, init_mode_conv=None, channel = 4):\n",
    "    \"\"\"Define n-gram CNN with different weight initializations for each channel.\n",
    "    \n",
    "    Args:\n",
    "    input_len: int. Length of input sequences.\n",
    "    output_size: int. Number of output classes.\n",
    "    vocab_size: int. Maximum value of n-gram encoding.\n",
    "    embedding_dim: int. Size of embedding layer.\n",
    "    verbose: bool. Whether or not to print model summary.\n",
    "    drop_out_pct: float. Drop-out rate.\n",
    "    conv_filters: int. Number of filters in the conv layer.\n",
    "    activation_fn: string. Activation function to use in the convolutional layer.\n",
    "    pool_size: int. Pool size for the max pooling layer.\n",
    "    learning: float. Learning rate for the model optimizer.\n",
    "    init_mode_embedding: list of keras.initializers. Initializers for the embedding layers.\n",
    "    init_mode_conv: list of keras.initializers. Initializers for the convolutional layers.\n",
    "    \n",
    "    Returns:\n",
    "    model: keras model object. \n",
    "    \"\"\"\n",
    "    if init_mode_embedding is None:\n",
    "        init_mode_embedding = [None] * channel\n",
    "    if init_mode_conv is None:\n",
    "        init_mode_conv = [None] * channel\n",
    "\n",
    "    channels = []\n",
    "    inputs = []\n",
    "\n",
    "    for i in range(channel):\n",
    "        input_shape = Input(shape=(input_len,))\n",
    "        inputs.append(input_shape)\n",
    "        embedding = Embedding(vocab_size, embedding_dim, embeddings_initializer=init_mode_embedding[i])(input_shape)\n",
    "        drop = AdaptiveDropout(drop_out_pct)(embedding)\n",
    "        conv = Conv1D(filters=conv_filters, kernel_size=i+3, activation=activation_fn, kernel_initializer=init_mode_conv[i])(drop)\n",
    "        pool = MaxPooling1D(pool_size=pool_size)(conv)\n",
    "        flat = Flatten()(pool)\n",
    "        channels.append(flat)\n",
    "\n",
    "    # Merge channels\n",
    "    merged = concatenate(channels)\n",
    "    \n",
    "    \n",
    "    output = Dense(output_size, activation='softmax')(merged)\n",
    "   \n",
    "    model = Model(inputs=inputs, outputs=output)\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=learning), metrics=['accuracy'])\n",
    "    \n",
    "    if verbose:\n",
    "        model.summary()\n",
    "        \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "def train_models(X_train, y_train, num_models=3, num_channels = 4):\n",
    "    models = []\n",
    "    n_samples = X_train.shape[0]\n",
    "    output_size = len(np.unique(y_train))\n",
    "\n",
    "    for _ in range(num_models):\n",
    "        indices = np.random.choice(n_samples, n_samples, replace=True)\n",
    "        X_sample = X_train[indices]\n",
    "        y_sample = y_train[indices]\n",
    "\n",
    "        model =  define_model2(300, 23, max_1gram + 1, 16, learning=0.1, drop_out_pct=0.0001, channel=num_channels)\n",
    "        model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        dropout_adjustment_callback = AdjustDropoutRateCallback(model)\n",
    "        model.fit([X_sample]*num_channels, y_sample, epochs=2, batch_size=16, \n",
    "                verbose = 1, validation_split = 0.2, callbacks=[dropout_adjustment_callback])\n",
    "        models.append(model)\n",
    "    \n",
    "    return models\n",
    "\n",
    "\n",
    "def majority_vote(models, X_test, num_channels = 4):\n",
    "\n",
    "    predictions = np.array([model.predict([X_test]*num_channels) for model in models])\n",
    "    # print(predictions)\n",
    "\n",
    "    predictions = np.sum(predictions, axis=0)\n",
    "\n",
    "    predictions = predictions/len(models)\n",
    "\n",
    "\n",
    "\n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 300)]        0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 300)]        0           []                               \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)           [(None, 300)]        0           []                               \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)           [(None, 300)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 300, 16)      2261424     ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, 300, 16)      2261424     ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_2 (Embedding)        (None, 300, 16)      2261424     ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_3 (Embedding)        (None, 300, 16)      2261424     ['input_4[0][0]']                \n",
      "                                                                                                  \n",
      " adaptive_dropout (AdaptiveDrop  (None, 300, 16)     1           ['embedding[0][0]']              \n",
      " out)                                                                                             \n",
      "                                                                                                  \n",
      " adaptive_dropout_1 (AdaptiveDr  (None, 300, 16)     1           ['embedding_1[0][0]']            \n",
      " opout)                                                                                           \n",
      "                                                                                                  \n",
      " adaptive_dropout_2 (AdaptiveDr  (None, 300, 16)     1           ['embedding_2[0][0]']            \n",
      " opout)                                                                                           \n",
      "                                                                                                  \n",
      " adaptive_dropout_3 (AdaptiveDr  (None, 300, 16)     1           ['embedding_3[0][0]']            \n",
      " opout)                                                                                           \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 298, 500)     24500       ['adaptive_dropout[0][0]']       \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 297, 500)     32500       ['adaptive_dropout_1[0][0]']     \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 296, 500)     40500       ['adaptive_dropout_2[0][0]']     \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 295, 500)     48500       ['adaptive_dropout_3[0][0]']     \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 149, 500)     0           ['conv1d[0][0]']                 \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPooling1D)  (None, 148, 500)    0           ['conv1d_1[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling1d_2 (MaxPooling1D)  (None, 148, 500)    0           ['conv1d_2[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling1d_3 (MaxPooling1D)  (None, 147, 500)    0           ['conv1d_3[0][0]']               \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 74500)        0           ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 74000)        0           ['max_pooling1d_1[0][0]']        \n",
      "                                                                                                  \n",
      " flatten_2 (Flatten)            (None, 74000)        0           ['max_pooling1d_2[0][0]']        \n",
      "                                                                                                  \n",
      " flatten_3 (Flatten)            (None, 73500)        0           ['max_pooling1d_3[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 296000)       0           ['flatten[0][0]',                \n",
      "                                                                  'flatten_1[0][0]',              \n",
      "                                                                  'flatten_2[0][0]',              \n",
      "                                                                  'flatten_3[0][0]']              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 23)           6808023     ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 15,999,723\n",
      "Trainable params: 15,999,719\n",
      "Non-trainable params: 4\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gram1_model2 = define_model2(300, 23, max_1gram + 1, 16, learning=0.1, drop_out_pct=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)           [(None, 300)]        0           []                               \n",
      "                                                                                                  \n",
      " input_6 (InputLayer)           [(None, 300)]        0           []                               \n",
      "                                                                                                  \n",
      " input_7 (InputLayer)           [(None, 300)]        0           []                               \n",
      "                                                                                                  \n",
      " input_8 (InputLayer)           [(None, 300)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding_4 (Embedding)        (None, 300, 16)      2261424     ['input_5[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_5 (Embedding)        (None, 300, 16)      2261424     ['input_6[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_6 (Embedding)        (None, 300, 16)      2261424     ['input_7[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_7 (Embedding)        (None, 300, 16)      2261424     ['input_8[0][0]']                \n",
      "                                                                                                  \n",
      " adaptive_dropout_4 (AdaptiveDr  (None, 300, 16)     1           ['embedding_4[0][0]']            \n",
      " opout)                                                                                           \n",
      "                                                                                                  \n",
      " adaptive_dropout_5 (AdaptiveDr  (None, 300, 16)     1           ['embedding_5[0][0]']            \n",
      " opout)                                                                                           \n",
      "                                                                                                  \n",
      " adaptive_dropout_6 (AdaptiveDr  (None, 300, 16)     1           ['embedding_6[0][0]']            \n",
      " opout)                                                                                           \n",
      "                                                                                                  \n",
      " adaptive_dropout_7 (AdaptiveDr  (None, 300, 16)     1           ['embedding_7[0][0]']            \n",
      " opout)                                                                                           \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 298, 500)     24500       ['adaptive_dropout_4[0][0]']     \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 297, 500)     32500       ['adaptive_dropout_5[0][0]']     \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 296, 500)     40500       ['adaptive_dropout_6[0][0]']     \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)              (None, 295, 500)     48500       ['adaptive_dropout_7[0][0]']     \n",
      "                                                                                                  \n",
      " max_pooling1d_4 (MaxPooling1D)  (None, 149, 500)    0           ['conv1d_4[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling1d_5 (MaxPooling1D)  (None, 148, 500)    0           ['conv1d_5[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling1d_6 (MaxPooling1D)  (None, 148, 500)    0           ['conv1d_6[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling1d_7 (MaxPooling1D)  (None, 147, 500)    0           ['conv1d_7[0][0]']               \n",
      "                                                                                                  \n",
      " flatten_4 (Flatten)            (None, 74500)        0           ['max_pooling1d_4[0][0]']        \n",
      "                                                                                                  \n",
      " flatten_5 (Flatten)            (None, 74000)        0           ['max_pooling1d_5[0][0]']        \n",
      "                                                                                                  \n",
      " flatten_6 (Flatten)            (None, 74000)        0           ['max_pooling1d_6[0][0]']        \n",
      "                                                                                                  \n",
      " flatten_7 (Flatten)            (None, 73500)        0           ['max_pooling1d_7[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 296000)       0           ['flatten_4[0][0]',              \n",
      "                                                                  'flatten_5[0][0]',              \n",
      "                                                                  'flatten_6[0][0]',              \n",
      "                                                                  'flatten_7[0][0]']              \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 23)           6808023     ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 15,999,723\n",
      "Trainable params: 15,999,719\n",
      "Non-trainable params: 4\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "658/658 [==============================] - ETA: 0s - loss: 0.9413 - accuracy: 0.7150Epoch 1: Current accuracy 0.72 is below threshold\n",
      "658/658 [==============================] - 91s 135ms/step - loss: 0.9413 - accuracy: 0.7150 - val_loss: 0.2441 - val_accuracy: 0.9289\n",
      "Epoch 2/2\n",
      "658/658 [==============================] - ETA: 0s - loss: 0.0278 - accuracy: 0.9928Epoch 2: Increasing dropout rate to 0.10\n",
      "658/658 [==============================] - 123s 187ms/step - loss: 0.0278 - accuracy: 0.9928 - val_loss: 0.1799 - val_accuracy: 0.9483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_9 (InputLayer)           [(None, 300)]        0           []                               \n",
      "                                                                                                  \n",
      " input_10 (InputLayer)          [(None, 300)]        0           []                               \n",
      "                                                                                                  \n",
      " input_11 (InputLayer)          [(None, 300)]        0           []                               \n",
      "                                                                                                  \n",
      " input_12 (InputLayer)          [(None, 300)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding_8 (Embedding)        (None, 300, 16)      2261424     ['input_9[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_9 (Embedding)        (None, 300, 16)      2261424     ['input_10[0][0]']               \n",
      "                                                                                                  \n",
      " embedding_10 (Embedding)       (None, 300, 16)      2261424     ['input_11[0][0]']               \n",
      "                                                                                                  \n",
      " embedding_11 (Embedding)       (None, 300, 16)      2261424     ['input_12[0][0]']               \n",
      "                                                                                                  \n",
      " adaptive_dropout_8 (AdaptiveDr  (None, 300, 16)     1           ['embedding_8[0][0]']            \n",
      " opout)                                                                                           \n",
      "                                                                                                  \n",
      " adaptive_dropout_9 (AdaptiveDr  (None, 300, 16)     1           ['embedding_9[0][0]']            \n",
      " opout)                                                                                           \n",
      "                                                                                                  \n",
      " adaptive_dropout_10 (AdaptiveD  (None, 300, 16)     1           ['embedding_10[0][0]']           \n",
      " ropout)                                                                                          \n",
      "                                                                                                  \n",
      " adaptive_dropout_11 (AdaptiveD  (None, 300, 16)     1           ['embedding_11[0][0]']           \n",
      " ropout)                                                                                          \n",
      "                                                                                                  \n",
      " conv1d_8 (Conv1D)              (None, 298, 500)     24500       ['adaptive_dropout_8[0][0]']     \n",
      "                                                                                                  \n",
      " conv1d_9 (Conv1D)              (None, 297, 500)     32500       ['adaptive_dropout_9[0][0]']     \n",
      "                                                                                                  \n",
      " conv1d_10 (Conv1D)             (None, 296, 500)     40500       ['adaptive_dropout_10[0][0]']    \n",
      "                                                                                                  \n",
      " conv1d_11 (Conv1D)             (None, 295, 500)     48500       ['adaptive_dropout_11[0][0]']    \n",
      "                                                                                                  \n",
      " max_pooling1d_8 (MaxPooling1D)  (None, 149, 500)    0           ['conv1d_8[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling1d_9 (MaxPooling1D)  (None, 148, 500)    0           ['conv1d_9[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling1d_10 (MaxPooling1D  (None, 148, 500)    0           ['conv1d_10[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " max_pooling1d_11 (MaxPooling1D  (None, 147, 500)    0           ['conv1d_11[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " flatten_8 (Flatten)            (None, 74500)        0           ['max_pooling1d_8[0][0]']        \n",
      "                                                                                                  \n",
      " flatten_9 (Flatten)            (None, 74000)        0           ['max_pooling1d_9[0][0]']        \n",
      "                                                                                                  \n",
      " flatten_10 (Flatten)           (None, 74000)        0           ['max_pooling1d_10[0][0]']       \n",
      "                                                                                                  \n",
      " flatten_11 (Flatten)           (None, 73500)        0           ['max_pooling1d_11[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 296000)       0           ['flatten_8[0][0]',              \n",
      "                                                                  'flatten_9[0][0]',              \n",
      "                                                                  'flatten_10[0][0]',             \n",
      "                                                                  'flatten_11[0][0]']             \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 23)           6808023     ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 15,999,723\n",
      "Trainable params: 15,999,719\n",
      "Non-trainable params: 4\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "658/658 [==============================] - ETA: 0s - loss: 0.9215 - accuracy: 0.7193Epoch 1: Current accuracy 0.72 is below threshold\n",
      "658/658 [==============================] - 136s 204ms/step - loss: 0.9215 - accuracy: 0.7193 - val_loss: 0.2013 - val_accuracy: 0.9342\n",
      "Epoch 2/2\n",
      "658/658 [==============================] - ETA: 0s - loss: 0.0249 - accuracy: 0.9932Epoch 2: Increasing dropout rate to 0.10\n",
      "658/658 [==============================] - 125s 189ms/step - loss: 0.0249 - accuracy: 0.9932 - val_loss: 0.1629 - val_accuracy: 0.9510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_13 (InputLayer)          [(None, 300)]        0           []                               \n",
      "                                                                                                  \n",
      " input_14 (InputLayer)          [(None, 300)]        0           []                               \n",
      "                                                                                                  \n",
      " input_15 (InputLayer)          [(None, 300)]        0           []                               \n",
      "                                                                                                  \n",
      " input_16 (InputLayer)          [(None, 300)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding_12 (Embedding)       (None, 300, 16)      2261424     ['input_13[0][0]']               \n",
      "                                                                                                  \n",
      " embedding_13 (Embedding)       (None, 300, 16)      2261424     ['input_14[0][0]']               \n",
      "                                                                                                  \n",
      " embedding_14 (Embedding)       (None, 300, 16)      2261424     ['input_15[0][0]']               \n",
      "                                                                                                  \n",
      " embedding_15 (Embedding)       (None, 300, 16)      2261424     ['input_16[0][0]']               \n",
      "                                                                                                  \n",
      " adaptive_dropout_12 (AdaptiveD  (None, 300, 16)     1           ['embedding_12[0][0]']           \n",
      " ropout)                                                                                          \n",
      "                                                                                                  \n",
      " adaptive_dropout_13 (AdaptiveD  (None, 300, 16)     1           ['embedding_13[0][0]']           \n",
      " ropout)                                                                                          \n",
      "                                                                                                  \n",
      " adaptive_dropout_14 (AdaptiveD  (None, 300, 16)     1           ['embedding_14[0][0]']           \n",
      " ropout)                                                                                          \n",
      "                                                                                                  \n",
      " adaptive_dropout_15 (AdaptiveD  (None, 300, 16)     1           ['embedding_15[0][0]']           \n",
      " ropout)                                                                                          \n",
      "                                                                                                  \n",
      " conv1d_12 (Conv1D)             (None, 298, 500)     24500       ['adaptive_dropout_12[0][0]']    \n",
      "                                                                                                  \n",
      " conv1d_13 (Conv1D)             (None, 297, 500)     32500       ['adaptive_dropout_13[0][0]']    \n",
      "                                                                                                  \n",
      " conv1d_14 (Conv1D)             (None, 296, 500)     40500       ['adaptive_dropout_14[0][0]']    \n",
      "                                                                                                  \n",
      " conv1d_15 (Conv1D)             (None, 295, 500)     48500       ['adaptive_dropout_15[0][0]']    \n",
      "                                                                                                  \n",
      " max_pooling1d_12 (MaxPooling1D  (None, 149, 500)    0           ['conv1d_12[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " max_pooling1d_13 (MaxPooling1D  (None, 148, 500)    0           ['conv1d_13[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " max_pooling1d_14 (MaxPooling1D  (None, 148, 500)    0           ['conv1d_14[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " max_pooling1d_15 (MaxPooling1D  (None, 147, 500)    0           ['conv1d_15[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " flatten_12 (Flatten)           (None, 74500)        0           ['max_pooling1d_12[0][0]']       \n",
      "                                                                                                  \n",
      " flatten_13 (Flatten)           (None, 74000)        0           ['max_pooling1d_13[0][0]']       \n",
      "                                                                                                  \n",
      " flatten_14 (Flatten)           (None, 74000)        0           ['max_pooling1d_14[0][0]']       \n",
      "                                                                                                  \n",
      " flatten_15 (Flatten)           (None, 73500)        0           ['max_pooling1d_15[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 296000)       0           ['flatten_12[0][0]',             \n",
      "                                                                  'flatten_13[0][0]',             \n",
      "                                                                  'flatten_14[0][0]',             \n",
      "                                                                  'flatten_15[0][0]']             \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 23)           6808023     ['concatenate_3[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 15,999,723\n",
      "Trainable params: 15,999,719\n",
      "Non-trainable params: 4\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "658/658 [==============================] - ETA: 0s - loss: 0.8982 - accuracy: 0.7305Epoch 1: Current accuracy 0.73 is below threshold\n",
      "658/658 [==============================] - 124s 185ms/step - loss: 0.8982 - accuracy: 0.7305 - val_loss: 0.2515 - val_accuracy: 0.9304\n",
      "Epoch 2/2\n",
      "658/658 [==============================] - ETA: 0s - loss: 0.0279 - accuracy: 0.9935Epoch 2: Increasing dropout rate to 0.10\n",
      "658/658 [==============================] - 121s 183ms/step - loss: 0.0279 - accuracy: 0.9935 - val_loss: 0.1805 - val_accuracy: 0.9498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_17 (InputLayer)          [(None, 300)]        0           []                               \n",
      "                                                                                                  \n",
      " input_18 (InputLayer)          [(None, 300)]        0           []                               \n",
      "                                                                                                  \n",
      " input_19 (InputLayer)          [(None, 300)]        0           []                               \n",
      "                                                                                                  \n",
      " input_20 (InputLayer)          [(None, 300)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding_16 (Embedding)       (None, 300, 16)      2261424     ['input_17[0][0]']               \n",
      "                                                                                                  \n",
      " embedding_17 (Embedding)       (None, 300, 16)      2261424     ['input_18[0][0]']               \n",
      "                                                                                                  \n",
      " embedding_18 (Embedding)       (None, 300, 16)      2261424     ['input_19[0][0]']               \n",
      "                                                                                                  \n",
      " embedding_19 (Embedding)       (None, 300, 16)      2261424     ['input_20[0][0]']               \n",
      "                                                                                                  \n",
      " adaptive_dropout_16 (AdaptiveD  (None, 300, 16)     1           ['embedding_16[0][0]']           \n",
      " ropout)                                                                                          \n",
      "                                                                                                  \n",
      " adaptive_dropout_17 (AdaptiveD  (None, 300, 16)     1           ['embedding_17[0][0]']           \n",
      " ropout)                                                                                          \n",
      "                                                                                                  \n",
      " adaptive_dropout_18 (AdaptiveD  (None, 300, 16)     1           ['embedding_18[0][0]']           \n",
      " ropout)                                                                                          \n",
      "                                                                                                  \n",
      " adaptive_dropout_19 (AdaptiveD  (None, 300, 16)     1           ['embedding_19[0][0]']           \n",
      " ropout)                                                                                          \n",
      "                                                                                                  \n",
      " conv1d_16 (Conv1D)             (None, 298, 500)     24500       ['adaptive_dropout_16[0][0]']    \n",
      "                                                                                                  \n",
      " conv1d_17 (Conv1D)             (None, 297, 500)     32500       ['adaptive_dropout_17[0][0]']    \n",
      "                                                                                                  \n",
      " conv1d_18 (Conv1D)             (None, 296, 500)     40500       ['adaptive_dropout_18[0][0]']    \n",
      "                                                                                                  \n",
      " conv1d_19 (Conv1D)             (None, 295, 500)     48500       ['adaptive_dropout_19[0][0]']    \n",
      "                                                                                                  \n",
      " max_pooling1d_16 (MaxPooling1D  (None, 149, 500)    0           ['conv1d_16[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " max_pooling1d_17 (MaxPooling1D  (None, 148, 500)    0           ['conv1d_17[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " max_pooling1d_18 (MaxPooling1D  (None, 148, 500)    0           ['conv1d_18[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " max_pooling1d_19 (MaxPooling1D  (None, 147, 500)    0           ['conv1d_19[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " flatten_16 (Flatten)           (None, 74500)        0           ['max_pooling1d_16[0][0]']       \n",
      "                                                                                                  \n",
      " flatten_17 (Flatten)           (None, 74000)        0           ['max_pooling1d_17[0][0]']       \n",
      "                                                                                                  \n",
      " flatten_18 (Flatten)           (None, 74000)        0           ['max_pooling1d_18[0][0]']       \n",
      "                                                                                                  \n",
      " flatten_19 (Flatten)           (None, 73500)        0           ['max_pooling1d_19[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 296000)       0           ['flatten_16[0][0]',             \n",
      "                                                                  'flatten_17[0][0]',             \n",
      "                                                                  'flatten_18[0][0]',             \n",
      "                                                                  'flatten_19[0][0]']             \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 23)           6808023     ['concatenate_4[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 15,999,723\n",
      "Trainable params: 15,999,719\n",
      "Non-trainable params: 4\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "658/658 [==============================] - ETA: 0s - loss: 0.9546 - accuracy: 0.7064Epoch 1: Current accuracy 0.71 is below threshold\n",
      "658/658 [==============================] - 124s 185ms/step - loss: 0.9546 - accuracy: 0.7064 - val_loss: 0.2995 - val_accuracy: 0.9168\n",
      "Epoch 2/2\n",
      "658/658 [==============================] - ETA: 0s - loss: 0.0331 - accuracy: 0.9912Epoch 2: Increasing dropout rate to 0.10\n",
      "658/658 [==============================] - 122s 186ms/step - loss: 0.0331 - accuracy: 0.9912 - val_loss: 0.2000 - val_accuracy: 0.9445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_21 (InputLayer)          [(None, 300)]        0           []                               \n",
      "                                                                                                  \n",
      " input_22 (InputLayer)          [(None, 300)]        0           []                               \n",
      "                                                                                                  \n",
      " input_23 (InputLayer)          [(None, 300)]        0           []                               \n",
      "                                                                                                  \n",
      " input_24 (InputLayer)          [(None, 300)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding_20 (Embedding)       (None, 300, 16)      2261424     ['input_21[0][0]']               \n",
      "                                                                                                  \n",
      " embedding_21 (Embedding)       (None, 300, 16)      2261424     ['input_22[0][0]']               \n",
      "                                                                                                  \n",
      " embedding_22 (Embedding)       (None, 300, 16)      2261424     ['input_23[0][0]']               \n",
      "                                                                                                  \n",
      " embedding_23 (Embedding)       (None, 300, 16)      2261424     ['input_24[0][0]']               \n",
      "                                                                                                  \n",
      " adaptive_dropout_20 (AdaptiveD  (None, 300, 16)     1           ['embedding_20[0][0]']           \n",
      " ropout)                                                                                          \n",
      "                                                                                                  \n",
      " adaptive_dropout_21 (AdaptiveD  (None, 300, 16)     1           ['embedding_21[0][0]']           \n",
      " ropout)                                                                                          \n",
      "                                                                                                  \n",
      " adaptive_dropout_22 (AdaptiveD  (None, 300, 16)     1           ['embedding_22[0][0]']           \n",
      " ropout)                                                                                          \n",
      "                                                                                                  \n",
      " adaptive_dropout_23 (AdaptiveD  (None, 300, 16)     1           ['embedding_23[0][0]']           \n",
      " ropout)                                                                                          \n",
      "                                                                                                  \n",
      " conv1d_20 (Conv1D)             (None, 298, 500)     24500       ['adaptive_dropout_20[0][0]']    \n",
      "                                                                                                  \n",
      " conv1d_21 (Conv1D)             (None, 297, 500)     32500       ['adaptive_dropout_21[0][0]']    \n",
      "                                                                                                  \n",
      " conv1d_22 (Conv1D)             (None, 296, 500)     40500       ['adaptive_dropout_22[0][0]']    \n",
      "                                                                                                  \n",
      " conv1d_23 (Conv1D)             (None, 295, 500)     48500       ['adaptive_dropout_23[0][0]']    \n",
      "                                                                                                  \n",
      " max_pooling1d_20 (MaxPooling1D  (None, 149, 500)    0           ['conv1d_20[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " max_pooling1d_21 (MaxPooling1D  (None, 148, 500)    0           ['conv1d_21[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " max_pooling1d_22 (MaxPooling1D  (None, 148, 500)    0           ['conv1d_22[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " max_pooling1d_23 (MaxPooling1D  (None, 147, 500)    0           ['conv1d_23[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " flatten_20 (Flatten)           (None, 74500)        0           ['max_pooling1d_20[0][0]']       \n",
      "                                                                                                  \n",
      " flatten_21 (Flatten)           (None, 74000)        0           ['max_pooling1d_21[0][0]']       \n",
      "                                                                                                  \n",
      " flatten_22 (Flatten)           (None, 74000)        0           ['max_pooling1d_22[0][0]']       \n",
      "                                                                                                  \n",
      " flatten_23 (Flatten)           (None, 73500)        0           ['max_pooling1d_23[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate)    (None, 296000)       0           ['flatten_20[0][0]',             \n",
      "                                                                  'flatten_21[0][0]',             \n",
      "                                                                  'flatten_22[0][0]',             \n",
      "                                                                  'flatten_23[0][0]']             \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 23)           6808023     ['concatenate_5[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 15,999,723\n",
      "Trainable params: 15,999,719\n",
      "Non-trainable params: 4\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "658/658 [==============================] - ETA: 0s - loss: 0.9099 - accuracy: 0.7225Epoch 1: Current accuracy 0.72 is below threshold\n",
      "658/658 [==============================] - 123s 184ms/step - loss: 0.9099 - accuracy: 0.7225 - val_loss: 0.2261 - val_accuracy: 0.9327\n",
      "Epoch 2/2\n",
      "658/658 [==============================] - ETA: 0s - loss: 0.0354 - accuracy: 0.9906Epoch 2: Increasing dropout rate to 0.10\n",
      "658/658 [==============================] - 122s 185ms/step - loss: 0.0354 - accuracy: 0.9906 - val_loss: 0.1580 - val_accuracy: 0.9487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_25 (InputLayer)          [(None, 300)]        0           []                               \n",
      "                                                                                                  \n",
      " input_26 (InputLayer)          [(None, 300)]        0           []                               \n",
      "                                                                                                  \n",
      " input_27 (InputLayer)          [(None, 300)]        0           []                               \n",
      "                                                                                                  \n",
      " input_28 (InputLayer)          [(None, 300)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding_24 (Embedding)       (None, 300, 16)      2261424     ['input_25[0][0]']               \n",
      "                                                                                                  \n",
      " embedding_25 (Embedding)       (None, 300, 16)      2261424     ['input_26[0][0]']               \n",
      "                                                                                                  \n",
      " embedding_26 (Embedding)       (None, 300, 16)      2261424     ['input_27[0][0]']               \n",
      "                                                                                                  \n",
      " embedding_27 (Embedding)       (None, 300, 16)      2261424     ['input_28[0][0]']               \n",
      "                                                                                                  \n",
      " adaptive_dropout_24 (AdaptiveD  (None, 300, 16)     1           ['embedding_24[0][0]']           \n",
      " ropout)                                                                                          \n",
      "                                                                                                  \n",
      " adaptive_dropout_25 (AdaptiveD  (None, 300, 16)     1           ['embedding_25[0][0]']           \n",
      " ropout)                                                                                          \n",
      "                                                                                                  \n",
      " adaptive_dropout_26 (AdaptiveD  (None, 300, 16)     1           ['embedding_26[0][0]']           \n",
      " ropout)                                                                                          \n",
      "                                                                                                  \n",
      " adaptive_dropout_27 (AdaptiveD  (None, 300, 16)     1           ['embedding_27[0][0]']           \n",
      " ropout)                                                                                          \n",
      "                                                                                                  \n",
      " conv1d_24 (Conv1D)             (None, 298, 500)     24500       ['adaptive_dropout_24[0][0]']    \n",
      "                                                                                                  \n",
      " conv1d_25 (Conv1D)             (None, 297, 500)     32500       ['adaptive_dropout_25[0][0]']    \n",
      "                                                                                                  \n",
      " conv1d_26 (Conv1D)             (None, 296, 500)     40500       ['adaptive_dropout_26[0][0]']    \n",
      "                                                                                                  \n",
      " conv1d_27 (Conv1D)             (None, 295, 500)     48500       ['adaptive_dropout_27[0][0]']    \n",
      "                                                                                                  \n",
      " max_pooling1d_24 (MaxPooling1D  (None, 149, 500)    0           ['conv1d_24[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " max_pooling1d_25 (MaxPooling1D  (None, 148, 500)    0           ['conv1d_25[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " max_pooling1d_26 (MaxPooling1D  (None, 148, 500)    0           ['conv1d_26[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " max_pooling1d_27 (MaxPooling1D  (None, 147, 500)    0           ['conv1d_27[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " flatten_24 (Flatten)           (None, 74500)        0           ['max_pooling1d_24[0][0]']       \n",
      "                                                                                                  \n",
      " flatten_25 (Flatten)           (None, 74000)        0           ['max_pooling1d_25[0][0]']       \n",
      "                                                                                                  \n",
      " flatten_26 (Flatten)           (None, 74000)        0           ['max_pooling1d_26[0][0]']       \n",
      "                                                                                                  \n",
      " flatten_27 (Flatten)           (None, 73500)        0           ['max_pooling1d_27[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate)    (None, 296000)       0           ['flatten_24[0][0]',             \n",
      "                                                                  'flatten_25[0][0]',             \n",
      "                                                                  'flatten_26[0][0]',             \n",
      "                                                                  'flatten_27[0][0]']             \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 23)           6808023     ['concatenate_6[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 15,999,723\n",
      "Trainable params: 15,999,719\n",
      "Non-trainable params: 4\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "658/658 [==============================] - ETA: 0s - loss: 0.9131 - accuracy: 0.7172Epoch 1: Current accuracy 0.72 is below threshold\n",
      "658/658 [==============================] - 123s 184ms/step - loss: 0.9131 - accuracy: 0.7172 - val_loss: 0.2741 - val_accuracy: 0.9111\n",
      "Epoch 2/2\n",
      "658/658 [==============================] - ETA: 0s - loss: 0.0337 - accuracy: 0.9905Epoch 2: Increasing dropout rate to 0.10\n",
      "658/658 [==============================] - 121s 184ms/step - loss: 0.0337 - accuracy: 0.9905 - val_loss: 0.2663 - val_accuracy: 0.9259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_29 (InputLayer)          [(None, 300)]        0           []                               \n",
      "                                                                                                  \n",
      " input_30 (InputLayer)          [(None, 300)]        0           []                               \n",
      "                                                                                                  \n",
      " input_31 (InputLayer)          [(None, 300)]        0           []                               \n",
      "                                                                                                  \n",
      " input_32 (InputLayer)          [(None, 300)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding_28 (Embedding)       (None, 300, 16)      2261424     ['input_29[0][0]']               \n",
      "                                                                                                  \n",
      " embedding_29 (Embedding)       (None, 300, 16)      2261424     ['input_30[0][0]']               \n",
      "                                                                                                  \n",
      " embedding_30 (Embedding)       (None, 300, 16)      2261424     ['input_31[0][0]']               \n",
      "                                                                                                  \n",
      " embedding_31 (Embedding)       (None, 300, 16)      2261424     ['input_32[0][0]']               \n",
      "                                                                                                  \n",
      " adaptive_dropout_28 (AdaptiveD  (None, 300, 16)     1           ['embedding_28[0][0]']           \n",
      " ropout)                                                                                          \n",
      "                                                                                                  \n",
      " adaptive_dropout_29 (AdaptiveD  (None, 300, 16)     1           ['embedding_29[0][0]']           \n",
      " ropout)                                                                                          \n",
      "                                                                                                  \n",
      " adaptive_dropout_30 (AdaptiveD  (None, 300, 16)     1           ['embedding_30[0][0]']           \n",
      " ropout)                                                                                          \n",
      "                                                                                                  \n",
      " adaptive_dropout_31 (AdaptiveD  (None, 300, 16)     1           ['embedding_31[0][0]']           \n",
      " ropout)                                                                                          \n",
      "                                                                                                  \n",
      " conv1d_28 (Conv1D)             (None, 298, 500)     24500       ['adaptive_dropout_28[0][0]']    \n",
      "                                                                                                  \n",
      " conv1d_29 (Conv1D)             (None, 297, 500)     32500       ['adaptive_dropout_29[0][0]']    \n",
      "                                                                                                  \n",
      " conv1d_30 (Conv1D)             (None, 296, 500)     40500       ['adaptive_dropout_30[0][0]']    \n",
      "                                                                                                  \n",
      " conv1d_31 (Conv1D)             (None, 295, 500)     48500       ['adaptive_dropout_31[0][0]']    \n",
      "                                                                                                  \n",
      " max_pooling1d_28 (MaxPooling1D  (None, 149, 500)    0           ['conv1d_28[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " max_pooling1d_29 (MaxPooling1D  (None, 148, 500)    0           ['conv1d_29[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " max_pooling1d_30 (MaxPooling1D  (None, 148, 500)    0           ['conv1d_30[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " max_pooling1d_31 (MaxPooling1D  (None, 147, 500)    0           ['conv1d_31[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " flatten_28 (Flatten)           (None, 74500)        0           ['max_pooling1d_28[0][0]']       \n",
      "                                                                                                  \n",
      " flatten_29 (Flatten)           (None, 74000)        0           ['max_pooling1d_29[0][0]']       \n",
      "                                                                                                  \n",
      " flatten_30 (Flatten)           (None, 74000)        0           ['max_pooling1d_30[0][0]']       \n",
      "                                                                                                  \n",
      " flatten_31 (Flatten)           (None, 73500)        0           ['max_pooling1d_31[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate_7 (Concatenate)    (None, 296000)       0           ['flatten_28[0][0]',             \n",
      "                                                                  'flatten_29[0][0]',             \n",
      "                                                                  'flatten_30[0][0]',             \n",
      "                                                                  'flatten_31[0][0]']             \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 23)           6808023     ['concatenate_7[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 15,999,723\n",
      "Trainable params: 15,999,719\n",
      "Non-trainable params: 4\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "658/658 [==============================] - ETA: 0s - loss: 0.8631 - accuracy: 0.7380Epoch 1: Current accuracy 0.74 is below threshold\n",
      "658/658 [==============================] - 123s 183ms/step - loss: 0.8631 - accuracy: 0.7380 - val_loss: 0.2012 - val_accuracy: 0.9411\n",
      "Epoch 2/2\n",
      "658/658 [==============================] - ETA: 0s - loss: 0.0283 - accuracy: 0.9923Epoch 2: Increasing dropout rate to 0.10\n",
      "658/658 [==============================] - 122s 185ms/step - loss: 0.0283 - accuracy: 0.9923 - val_loss: 0.2335 - val_accuracy: 0.9380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_33 (InputLayer)          [(None, 300)]        0           []                               \n",
      "                                                                                                  \n",
      " input_34 (InputLayer)          [(None, 300)]        0           []                               \n",
      "                                                                                                  \n",
      " input_35 (InputLayer)          [(None, 300)]        0           []                               \n",
      "                                                                                                  \n",
      " input_36 (InputLayer)          [(None, 300)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding_32 (Embedding)       (None, 300, 16)      2261424     ['input_33[0][0]']               \n",
      "                                                                                                  \n",
      " embedding_33 (Embedding)       (None, 300, 16)      2261424     ['input_34[0][0]']               \n",
      "                                                                                                  \n",
      " embedding_34 (Embedding)       (None, 300, 16)      2261424     ['input_35[0][0]']               \n",
      "                                                                                                  \n",
      " embedding_35 (Embedding)       (None, 300, 16)      2261424     ['input_36[0][0]']               \n",
      "                                                                                                  \n",
      " adaptive_dropout_32 (AdaptiveD  (None, 300, 16)     1           ['embedding_32[0][0]']           \n",
      " ropout)                                                                                          \n",
      "                                                                                                  \n",
      " adaptive_dropout_33 (AdaptiveD  (None, 300, 16)     1           ['embedding_33[0][0]']           \n",
      " ropout)                                                                                          \n",
      "                                                                                                  \n",
      " adaptive_dropout_34 (AdaptiveD  (None, 300, 16)     1           ['embedding_34[0][0]']           \n",
      " ropout)                                                                                          \n",
      "                                                                                                  \n",
      " adaptive_dropout_35 (AdaptiveD  (None, 300, 16)     1           ['embedding_35[0][0]']           \n",
      " ropout)                                                                                          \n",
      "                                                                                                  \n",
      " conv1d_32 (Conv1D)             (None, 298, 500)     24500       ['adaptive_dropout_32[0][0]']    \n",
      "                                                                                                  \n",
      " conv1d_33 (Conv1D)             (None, 297, 500)     32500       ['adaptive_dropout_33[0][0]']    \n",
      "                                                                                                  \n",
      " conv1d_34 (Conv1D)             (None, 296, 500)     40500       ['adaptive_dropout_34[0][0]']    \n",
      "                                                                                                  \n",
      " conv1d_35 (Conv1D)             (None, 295, 500)     48500       ['adaptive_dropout_35[0][0]']    \n",
      "                                                                                                  \n",
      " max_pooling1d_32 (MaxPooling1D  (None, 149, 500)    0           ['conv1d_32[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " max_pooling1d_33 (MaxPooling1D  (None, 148, 500)    0           ['conv1d_33[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " max_pooling1d_34 (MaxPooling1D  (None, 148, 500)    0           ['conv1d_34[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " max_pooling1d_35 (MaxPooling1D  (None, 147, 500)    0           ['conv1d_35[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " flatten_32 (Flatten)           (None, 74500)        0           ['max_pooling1d_32[0][0]']       \n",
      "                                                                                                  \n",
      " flatten_33 (Flatten)           (None, 74000)        0           ['max_pooling1d_33[0][0]']       \n",
      "                                                                                                  \n",
      " flatten_34 (Flatten)           (None, 74000)        0           ['max_pooling1d_34[0][0]']       \n",
      "                                                                                                  \n",
      " flatten_35 (Flatten)           (None, 73500)        0           ['max_pooling1d_35[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate_8 (Concatenate)    (None, 296000)       0           ['flatten_32[0][0]',             \n",
      "                                                                  'flatten_33[0][0]',             \n",
      "                                                                  'flatten_34[0][0]',             \n",
      "                                                                  'flatten_35[0][0]']             \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 23)           6808023     ['concatenate_8[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 15,999,723\n",
      "Trainable params: 15,999,719\n",
      "Non-trainable params: 4\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "658/658 [==============================] - ETA: 0s - loss: 0.8854 - accuracy: 0.7308Epoch 1: Current accuracy 0.73 is below threshold\n",
      "658/658 [==============================] - 122s 182ms/step - loss: 0.8854 - accuracy: 0.7308 - val_loss: 0.2314 - val_accuracy: 0.9304\n",
      "Epoch 2/2\n",
      "658/658 [==============================] - ETA: 0s - loss: 0.0269 - accuracy: 0.9933Epoch 2: Increasing dropout rate to 0.10\n",
      "658/658 [==============================] - 120s 183ms/step - loss: 0.0269 - accuracy: 0.9933 - val_loss: 0.1776 - val_accuracy: 0.9445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_9\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_37 (InputLayer)          [(None, 300)]        0           []                               \n",
      "                                                                                                  \n",
      " input_38 (InputLayer)          [(None, 300)]        0           []                               \n",
      "                                                                                                  \n",
      " input_39 (InputLayer)          [(None, 300)]        0           []                               \n",
      "                                                                                                  \n",
      " input_40 (InputLayer)          [(None, 300)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding_36 (Embedding)       (None, 300, 16)      2261424     ['input_37[0][0]']               \n",
      "                                                                                                  \n",
      " embedding_37 (Embedding)       (None, 300, 16)      2261424     ['input_38[0][0]']               \n",
      "                                                                                                  \n",
      " embedding_38 (Embedding)       (None, 300, 16)      2261424     ['input_39[0][0]']               \n",
      "                                                                                                  \n",
      " embedding_39 (Embedding)       (None, 300, 16)      2261424     ['input_40[0][0]']               \n",
      "                                                                                                  \n",
      " adaptive_dropout_36 (AdaptiveD  (None, 300, 16)     1           ['embedding_36[0][0]']           \n",
      " ropout)                                                                                          \n",
      "                                                                                                  \n",
      " adaptive_dropout_37 (AdaptiveD  (None, 300, 16)     1           ['embedding_37[0][0]']           \n",
      " ropout)                                                                                          \n",
      "                                                                                                  \n",
      " adaptive_dropout_38 (AdaptiveD  (None, 300, 16)     1           ['embedding_38[0][0]']           \n",
      " ropout)                                                                                          \n",
      "                                                                                                  \n",
      " adaptive_dropout_39 (AdaptiveD  (None, 300, 16)     1           ['embedding_39[0][0]']           \n",
      " ropout)                                                                                          \n",
      "                                                                                                  \n",
      " conv1d_36 (Conv1D)             (None, 298, 500)     24500       ['adaptive_dropout_36[0][0]']    \n",
      "                                                                                                  \n",
      " conv1d_37 (Conv1D)             (None, 297, 500)     32500       ['adaptive_dropout_37[0][0]']    \n",
      "                                                                                                  \n",
      " conv1d_38 (Conv1D)             (None, 296, 500)     40500       ['adaptive_dropout_38[0][0]']    \n",
      "                                                                                                  \n",
      " conv1d_39 (Conv1D)             (None, 295, 500)     48500       ['adaptive_dropout_39[0][0]']    \n",
      "                                                                                                  \n",
      " max_pooling1d_36 (MaxPooling1D  (None, 149, 500)    0           ['conv1d_36[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " max_pooling1d_37 (MaxPooling1D  (None, 148, 500)    0           ['conv1d_37[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " max_pooling1d_38 (MaxPooling1D  (None, 148, 500)    0           ['conv1d_38[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " max_pooling1d_39 (MaxPooling1D  (None, 147, 500)    0           ['conv1d_39[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " flatten_36 (Flatten)           (None, 74500)        0           ['max_pooling1d_36[0][0]']       \n",
      "                                                                                                  \n",
      " flatten_37 (Flatten)           (None, 74000)        0           ['max_pooling1d_37[0][0]']       \n",
      "                                                                                                  \n",
      " flatten_38 (Flatten)           (None, 74000)        0           ['max_pooling1d_38[0][0]']       \n",
      "                                                                                                  \n",
      " flatten_39 (Flatten)           (None, 73500)        0           ['max_pooling1d_39[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate_9 (Concatenate)    (None, 296000)       0           ['flatten_36[0][0]',             \n",
      "                                                                  'flatten_37[0][0]',             \n",
      "                                                                  'flatten_38[0][0]',             \n",
      "                                                                  'flatten_39[0][0]']             \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 23)           6808023     ['concatenate_9[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 15,999,723\n",
      "Trainable params: 15,999,719\n",
      "Non-trainable params: 4\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "658/658 [==============================] - ETA: 0s - loss: 0.9162 - accuracy: 0.7196Epoch 1: Current accuracy 0.72 is below threshold\n",
      "658/658 [==============================] - 124s 186ms/step - loss: 0.9162 - accuracy: 0.7196 - val_loss: 0.2027 - val_accuracy: 0.9411\n",
      "Epoch 2/2\n",
      "658/658 [==============================] - ETA: 0s - loss: 0.0240 - accuracy: 0.9933Epoch 2: Increasing dropout rate to 0.10\n",
      "658/658 [==============================] - 121s 184ms/step - loss: 0.0240 - accuracy: 0.9933 - val_loss: 0.2693 - val_accuracy: 0.9244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_10\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_41 (InputLayer)          [(None, 300)]        0           []                               \n",
      "                                                                                                  \n",
      " input_42 (InputLayer)          [(None, 300)]        0           []                               \n",
      "                                                                                                  \n",
      " input_43 (InputLayer)          [(None, 300)]        0           []                               \n",
      "                                                                                                  \n",
      " input_44 (InputLayer)          [(None, 300)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding_40 (Embedding)       (None, 300, 16)      2261424     ['input_41[0][0]']               \n",
      "                                                                                                  \n",
      " embedding_41 (Embedding)       (None, 300, 16)      2261424     ['input_42[0][0]']               \n",
      "                                                                                                  \n",
      " embedding_42 (Embedding)       (None, 300, 16)      2261424     ['input_43[0][0]']               \n",
      "                                                                                                  \n",
      " embedding_43 (Embedding)       (None, 300, 16)      2261424     ['input_44[0][0]']               \n",
      "                                                                                                  \n",
      " adaptive_dropout_40 (AdaptiveD  (None, 300, 16)     1           ['embedding_40[0][0]']           \n",
      " ropout)                                                                                          \n",
      "                                                                                                  \n",
      " adaptive_dropout_41 (AdaptiveD  (None, 300, 16)     1           ['embedding_41[0][0]']           \n",
      " ropout)                                                                                          \n",
      "                                                                                                  \n",
      " adaptive_dropout_42 (AdaptiveD  (None, 300, 16)     1           ['embedding_42[0][0]']           \n",
      " ropout)                                                                                          \n",
      "                                                                                                  \n",
      " adaptive_dropout_43 (AdaptiveD  (None, 300, 16)     1           ['embedding_43[0][0]']           \n",
      " ropout)                                                                                          \n",
      "                                                                                                  \n",
      " conv1d_40 (Conv1D)             (None, 298, 500)     24500       ['adaptive_dropout_40[0][0]']    \n",
      "                                                                                                  \n",
      " conv1d_41 (Conv1D)             (None, 297, 500)     32500       ['adaptive_dropout_41[0][0]']    \n",
      "                                                                                                  \n",
      " conv1d_42 (Conv1D)             (None, 296, 500)     40500       ['adaptive_dropout_42[0][0]']    \n",
      "                                                                                                  \n",
      " conv1d_43 (Conv1D)             (None, 295, 500)     48500       ['adaptive_dropout_43[0][0]']    \n",
      "                                                                                                  \n",
      " max_pooling1d_40 (MaxPooling1D  (None, 149, 500)    0           ['conv1d_40[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " max_pooling1d_41 (MaxPooling1D  (None, 148, 500)    0           ['conv1d_41[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " max_pooling1d_42 (MaxPooling1D  (None, 148, 500)    0           ['conv1d_42[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " max_pooling1d_43 (MaxPooling1D  (None, 147, 500)    0           ['conv1d_43[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " flatten_40 (Flatten)           (None, 74500)        0           ['max_pooling1d_40[0][0]']       \n",
      "                                                                                                  \n",
      " flatten_41 (Flatten)           (None, 74000)        0           ['max_pooling1d_41[0][0]']       \n",
      "                                                                                                  \n",
      " flatten_42 (Flatten)           (None, 74000)        0           ['max_pooling1d_42[0][0]']       \n",
      "                                                                                                  \n",
      " flatten_43 (Flatten)           (None, 73500)        0           ['max_pooling1d_43[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate_10 (Concatenate)   (None, 296000)       0           ['flatten_40[0][0]',             \n",
      "                                                                  'flatten_41[0][0]',             \n",
      "                                                                  'flatten_42[0][0]',             \n",
      "                                                                  'flatten_43[0][0]']             \n",
      "                                                                                                  \n",
      " dense_10 (Dense)               (None, 23)           6808023     ['concatenate_10[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 15,999,723\n",
      "Trainable params: 15,999,719\n",
      "Non-trainable params: 4\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "658/658 [==============================] - ETA: 0s - loss: 0.9688 - accuracy: 0.7036Epoch 1: Current accuracy 0.70 is below threshold\n",
      "658/658 [==============================] - 122s 182ms/step - loss: 0.9688 - accuracy: 0.7036 - val_loss: 0.2213 - val_accuracy: 0.9304\n",
      "Epoch 2/2\n",
      "658/658 [==============================] - ETA: 0s - loss: 0.0295 - accuracy: 0.9906Epoch 2: Increasing dropout rate to 0.10\n",
      "658/658 [==============================] - 133s 202ms/step - loss: 0.0295 - accuracy: 0.9906 - val_loss: 0.1728 - val_accuracy: 0.9498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_11\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_45 (InputLayer)          [(None, 300)]        0           []                               \n",
      "                                                                                                  \n",
      " input_46 (InputLayer)          [(None, 300)]        0           []                               \n",
      "                                                                                                  \n",
      " input_47 (InputLayer)          [(None, 300)]        0           []                               \n",
      "                                                                                                  \n",
      " input_48 (InputLayer)          [(None, 300)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding_44 (Embedding)       (None, 300, 16)      2261424     ['input_45[0][0]']               \n",
      "                                                                                                  \n",
      " embedding_45 (Embedding)       (None, 300, 16)      2261424     ['input_46[0][0]']               \n",
      "                                                                                                  \n",
      " embedding_46 (Embedding)       (None, 300, 16)      2261424     ['input_47[0][0]']               \n",
      "                                                                                                  \n",
      " embedding_47 (Embedding)       (None, 300, 16)      2261424     ['input_48[0][0]']               \n",
      "                                                                                                  \n",
      " adaptive_dropout_44 (AdaptiveD  (None, 300, 16)     1           ['embedding_44[0][0]']           \n",
      " ropout)                                                                                          \n",
      "                                                                                                  \n",
      " adaptive_dropout_45 (AdaptiveD  (None, 300, 16)     1           ['embedding_45[0][0]']           \n",
      " ropout)                                                                                          \n",
      "                                                                                                  \n",
      " adaptive_dropout_46 (AdaptiveD  (None, 300, 16)     1           ['embedding_46[0][0]']           \n",
      " ropout)                                                                                          \n",
      "                                                                                                  \n",
      " adaptive_dropout_47 (AdaptiveD  (None, 300, 16)     1           ['embedding_47[0][0]']           \n",
      " ropout)                                                                                          \n",
      "                                                                                                  \n",
      " conv1d_44 (Conv1D)             (None, 298, 500)     24500       ['adaptive_dropout_44[0][0]']    \n",
      "                                                                                                  \n",
      " conv1d_45 (Conv1D)             (None, 297, 500)     32500       ['adaptive_dropout_45[0][0]']    \n",
      "                                                                                                  \n",
      " conv1d_46 (Conv1D)             (None, 296, 500)     40500       ['adaptive_dropout_46[0][0]']    \n",
      "                                                                                                  \n",
      " conv1d_47 (Conv1D)             (None, 295, 500)     48500       ['adaptive_dropout_47[0][0]']    \n",
      "                                                                                                  \n",
      " max_pooling1d_44 (MaxPooling1D  (None, 149, 500)    0           ['conv1d_44[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " max_pooling1d_45 (MaxPooling1D  (None, 148, 500)    0           ['conv1d_45[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " max_pooling1d_46 (MaxPooling1D  (None, 148, 500)    0           ['conv1d_46[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " max_pooling1d_47 (MaxPooling1D  (None, 147, 500)    0           ['conv1d_47[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " flatten_44 (Flatten)           (None, 74500)        0           ['max_pooling1d_44[0][0]']       \n",
      "                                                                                                  \n",
      " flatten_45 (Flatten)           (None, 74000)        0           ['max_pooling1d_45[0][0]']       \n",
      "                                                                                                  \n",
      " flatten_46 (Flatten)           (None, 74000)        0           ['max_pooling1d_46[0][0]']       \n",
      "                                                                                                  \n",
      " flatten_47 (Flatten)           (None, 73500)        0           ['max_pooling1d_47[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate_11 (Concatenate)   (None, 296000)       0           ['flatten_44[0][0]',             \n",
      "                                                                  'flatten_45[0][0]',             \n",
      "                                                                  'flatten_46[0][0]',             \n",
      "                                                                  'flatten_47[0][0]']             \n",
      "                                                                                                  \n",
      " dense_11 (Dense)               (None, 23)           6808023     ['concatenate_11[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 15,999,723\n",
      "Trainable params: 15,999,719\n",
      "Non-trainable params: 4\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "658/658 [==============================] - ETA: 0s - loss: 0.9159 - accuracy: 0.7200Epoch 1: Current accuracy 0.72 is below threshold\n",
      "658/658 [==============================] - 195s 289ms/step - loss: 0.9159 - accuracy: 0.7200 - val_loss: 0.2196 - val_accuracy: 0.9396\n",
      "Epoch 2/2\n",
      "658/658 [==============================] - ETA: 0s - loss: 0.0331 - accuracy: 0.9904Epoch 2: Increasing dropout rate to 0.10\n",
      "658/658 [==============================] - 176s 267ms/step - loss: 0.0331 - accuracy: 0.9904 - val_loss: 0.2061 - val_accuracy: 0.9437\n"
     ]
    }
   ],
   "source": [
    "models = train_models(X_train=gram1, y_train=author_hot, num_models=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "412/412 [==============================] - 16s 38ms/step\n",
      "412/412 [==============================] - 14s 35ms/step\n",
      "412/412 [==============================] - 16s 38ms/step\n",
      "412/412 [==============================] - 16s 40ms/step\n",
      "412/412 [==============================] - 16s 39ms/step\n",
      "412/412 [==============================] - 17s 42ms/step\n",
      "412/412 [==============================] - 21s 50ms/step\n",
      "412/412 [==============================] - 21s 51ms/step\n",
      "412/412 [==============================] - 23s 55ms/step\n",
      "412/412 [==============================] - 24s 58ms/step\n",
      "412/412 [==============================] - 24s 58ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = majority_vote(models, gram1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.99908775\n"
     ]
    }
   ],
   "source": [
    "true = np.argmax(author_hot, axis = 1)\n",
    "\n",
    "accuracy = tf.metrics.Accuracy()\n",
    "\n",
    "accuracy.update_state(true, np.argmax(predictions, axis = 1))\n",
    "\n",
    "print(\"Accuracy:\", accuracy.result().numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csci1470pj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
